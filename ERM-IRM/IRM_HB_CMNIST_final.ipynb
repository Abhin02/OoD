{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to run this notebook\n",
    "\n",
    "In this notebook, we present the comparisons for HB-MNIST: Confounded and anti-causal colored MNIST.\n",
    "Run all the cells sequentially from top to bottom; we have commented the cells to help the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import cProfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_construct import * ## contains functions for constructing data \n",
    "from IRM_methods import *    ## contains IRM and ERM methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample complexity on HB-CMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr1000\n",
      "trial 0\n",
      "60000\n",
      "(232,)\n",
      "(268,)\n",
      "(225,)\n",
      "(275,)\n",
      "(5441,)\n",
      "(4559,)\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 749us/sample - loss: 1.7436 - acc: 0.6440\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 1.6325 - acc: 0.7630\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 1.5921 - acc: 0.7660\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 1.5272 - acc: 0.7740\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 1.4850 - acc: 0.7740\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 1.4502 - acc: 0.7900\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1.4065 - acc: 0.8000\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 1.3620 - acc: 0.8080\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 1.3267 - acc: 0.8020\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 1.2909 - acc: 0.8180\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 1.2505 - acc: 0.8330\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 1.2146 - acc: 0.8460\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 1.1795 - acc: 0.8610\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 1.1416 - acc: 0.8660\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 1.1062 - acc: 0.8620\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 1.0718 - acc: 0.8880\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 1.0351 - acc: 0.9090\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 1.0032 - acc: 0.9090\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.9674 - acc: 0.9280\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.9351 - acc: 0.9290\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.9032 - acc: 0.9440\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.8719 - acc: 0.9570\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.8424 - acc: 0.9570\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.8109 - acc: 0.9670\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.7824 - acc: 0.9720\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.7558 - acc: 0.9820\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.7295 - acc: 0.9860\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.7074 - acc: 0.9900\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.6844 - acc: 0.9890\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.6622 - acc: 0.9900\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.6442 - acc: 0.9960\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.6270 - acc: 0.9950\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.6074 - acc: 0.9960\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.5930 - acc: 0.9970\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.5782 - acc: 0.9970\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.5638 - acc: 0.9970\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.5509 - acc: 0.9970\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.5395 - acc: 0.9970\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 0.5274 - acc: 0.9970\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.5175 - acc: 0.9960\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.5063 - acc: 0.9980\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.4960 - acc: 0.9990\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.4867 - acc: 0.9980\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.4775 - acc: 0.9980\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.4683 - acc: 0.9980\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.4601 - acc: 0.9970\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.4518 - acc: 0.9980\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.4433 - acc: 0.9980\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.4366 - acc: 0.9980\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 0.4291 - acc: 0.9970\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.4207 - acc: 0.9970\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.4142 - acc: 0.9970\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.4083 - acc: 0.9970\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.3993 - acc: 0.9980\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.3954 - acc: 0.9970\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.3871 - acc: 0.9980\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.3813 - acc: 0.9960\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.3748 - acc: 0.9970\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.3683 - acc: 0.9980\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.3629 - acc: 0.9980\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.3574 - acc: 0.9960\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.3511 - acc: 0.9980\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.3460 - acc: 0.9970\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.3406 - acc: 0.9980\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.3353 - acc: 0.9970\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.3298 - acc: 0.9980\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.3254 - acc: 0.9970\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.3198 - acc: 0.9980\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 0.3153 - acc: 0.9980\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.3109 - acc: 0.9980\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.3057 - acc: 0.9980\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.3015 - acc: 0.9980\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.2977 - acc: 0.9970\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.2946 - acc: 0.9960\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.2886 - acc: 0.9980\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.2855 - acc: 0.9970\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.2807 - acc: 0.9980\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.2765 - acc: 0.9980\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.2734 - acc: 0.9980\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.2688 - acc: 0.9980\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.2662 - acc: 0.9980\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.2623 - acc: 0.9980\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.2582 - acc: 0.9980\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.2550 - acc: 0.9980\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.2514 - acc: 0.9980\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.2488 - acc: 0.9970\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.2442 - acc: 0.9980\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.2421 - acc: 0.9980\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.2389 - acc: 0.9970\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.2346 - acc: 0.9980\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.2328 - acc: 0.9980\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.2298 - acc: 0.9980\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.2264 - acc: 0.9980\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.2232 - acc: 0.9980\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.2209 - acc: 0.9970\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.2172 - acc: 0.9980\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.2153 - acc: 0.9970\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.2121 - acc: 0.9970\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.2099 - acc: 0.9980\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.2076 - acc: 0.9970\n",
      "Training accuracy:0.9980000257492065\n",
      "Testing accuracy:0.3465999960899353\n",
      "Training accuracy:0.9975000023841858\n",
      "Validation accuracy:0.9975000023841858\n",
      "Testing accuracy:0.3179999887943268\n",
      "total time: 168.40685081481934\n",
      "tr5000\n",
      "trial 0\n",
      "60000\n",
      "(1174,)\n",
      "(1326,)\n",
      "(1137,)\n",
      "(1363,)\n",
      "(5445,)\n",
      "(4555,)\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 144us/sample - loss: 1.5952 - acc: 0.7656\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 0s 48us/sample - loss: 1.4101 - acc: 0.8002\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 0s 51us/sample - loss: 1.2780 - acc: 0.8070\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 1.1666 - acc: 0.8144\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 1.0690 - acc: 0.8222\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.9865 - acc: 0.8272\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.9188 - acc: 0.8348\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 0s 52us/sample - loss: 0.8587 - acc: 0.8428\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.8045 - acc: 0.8480\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.7483 - acc: 0.8654\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.7022 - acc: 0.8780\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.6627 - acc: 0.8894\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.6261 - acc: 0.8938\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.5934 - acc: 0.8986\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 0s 52us/sample - loss: 0.5524 - acc: 0.9256\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 0s 56us/sample - loss: 0.5107 - acc: 0.9386\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 0s 60us/sample - loss: 0.4800 - acc: 0.9484\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.4490 - acc: 0.9594\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.4287 - acc: 0.9630\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.4006 - acc: 0.9692\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 0s 58us/sample - loss: 0.3923 - acc: 0.9670\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.3878 - acc: 0.9668\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.3633 - acc: 0.9774\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 0s 65us/sample - loss: 0.3404 - acc: 0.9834\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 0s 70us/sample - loss: 0.3300 - acc: 0.9860\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 0s 72us/sample - loss: 0.3174 - acc: 0.9868\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 0s 68us/sample - loss: 0.3124 - acc: 0.9852\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.3025 - acc: 0.9880\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 0s 69us/sample - loss: 0.3057 - acc: 0.9848\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.2869 - acc: 0.9900\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.2750 - acc: 0.9908\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.2688 - acc: 0.9918\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 0s 72us/sample - loss: 0.2643 - acc: 0.9898\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 0s 70us/sample - loss: 0.2580 - acc: 0.9918\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.2530 - acc: 0.9906\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.2469 - acc: 0.9924\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.2429 - acc: 0.9908\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.2412 - acc: 0.9904\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.2341 - acc: 0.9914\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 0s 62us/sample - loss: 0.2282 - acc: 0.9928\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 0s 56us/sample - loss: 0.2270 - acc: 0.9918\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.2264 - acc: 0.9914\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.2221 - acc: 0.9928\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 0s 66us/sample - loss: 0.2202 - acc: 0.9908\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.2214 - acc: 0.9894\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.2229 - acc: 0.9870\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.2192 - acc: 0.9876\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.2167 - acc: 0.9862\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.2132 - acc: 0.9904\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.2000 - acc: 0.9914\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1973 - acc: 0.9920\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.1883 - acc: 0.9926\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 0s 62us/sample - loss: 0.1871 - acc: 0.9920\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 0s 66us/sample - loss: 0.1850 - acc: 0.9924\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 0s 65us/sample - loss: 0.1840 - acc: 0.9908\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 0s 58us/sample - loss: 0.1755 - acc: 0.9932\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.1740 - acc: 0.9918\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.1718 - acc: 0.9932\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.1725 - acc: 0.9924\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 0s 68us/sample - loss: 0.1662 - acc: 0.9934\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 0s 67us/sample - loss: 0.1647 - acc: 0.9922\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 0s 60us/sample - loss: 0.1642 - acc: 0.9940\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 0s 62us/sample - loss: 0.1614 - acc: 0.9926\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.1585 - acc: 0.9928\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 0s 58us/sample - loss: 0.1606 - acc: 0.9916\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 0s 51us/sample - loss: 0.1597 - acc: 0.9922\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.1616 - acc: 0.9912\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 0s 55us/sample - loss: 0.1565 - acc: 0.9934\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 0.1573 - acc: 0.9920\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 0s 53us/sample - loss: 0.1529 - acc: 0.9932\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 0s 58us/sample - loss: 0.1486 - acc: 0.9916\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.1460 - acc: 0.9928\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.1453 - acc: 0.9910\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 0s 60us/sample - loss: 0.1414 - acc: 0.9920\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.1427 - acc: 0.9914\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 0s 60us/sample - loss: 0.1420 - acc: 0.9926\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.1433 - acc: 0.9920\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.1406 - acc: 0.9928\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.1368 - acc: 0.9922\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.1354 - acc: 0.9918\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.1378 - acc: 0.9910\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 0.1334 - acc: 0.9922\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 0s 53us/sample - loss: 0.1320 - acc: 0.9916\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 0s 62us/sample - loss: 0.1342 - acc: 0.9918\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 0s 52us/sample - loss: 0.1334 - acc: 0.9924\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.1334 - acc: 0.9930\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 0s 58us/sample - loss: 0.1288 - acc: 0.9914\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 0s 62us/sample - loss: 0.1256 - acc: 0.9930\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1245 - acc: 0.9926\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 0s 56us/sample - loss: 0.1248 - acc: 0.9920\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.1317 - acc: 0.9916\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.1466 - acc: 0.9828\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1504 - acc: 0.9824\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 0.1338 - acc: 0.9914\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 0s 61us/sample - loss: 0.1335 - acc: 0.9894\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 0s 53us/sample - loss: 0.1260 - acc: 0.9906\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 0s 55us/sample - loss: 0.1217 - acc: 0.9916\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1186 - acc: 0.9924\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 0s 55us/sample - loss: 0.1181 - acc: 0.9924\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 0s 63us/sample - loss: 0.1149 - acc: 0.9932\n",
      "Training accuracy:0.9941999912261963\n",
      "Testing accuracy:0.38659998774528503\n",
      "Training accuracy:0.6129999756813049\n",
      "Validation accuracy:0.6129999756813049\n",
      "Testing accuracy:0.5210000276565552\n",
      "total time: 250.37980890274048\n",
      "tr10000\n",
      "trial 0\n",
      "60000\n",
      "(2305,)\n",
      "(2695,)\n",
      "(2258,)\n",
      "(2742,)\n",
      "(5467,)\n",
      "(4533,)\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 1.5246 - acc: 0.7704\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 1.2569 - acc: 0.7872\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 1.0771 - acc: 0.7941\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.9475 - acc: 0.7995\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.8546 - acc: 0.8086\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.7836 - acc: 0.8152\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.7277 - acc: 0.8246\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.6830 - acc: 0.8311\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.6468 - acc: 0.8377\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.6041 - acc: 0.8513\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.5757 - acc: 0.8575\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.5413 - acc: 0.8717\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.5186 - acc: 0.8750\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.4909 - acc: 0.8890\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.4630 - acc: 0.8979\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.4278 - acc: 0.9173\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.3996 - acc: 0.9261\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.3746 - acc: 0.9367\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.3584 - acc: 0.9410\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.3392 - acc: 0.9478\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.3154 - acc: 0.9567\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.3016 - acc: 0.9605\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2929 - acc: 0.9643\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.2919 - acc: 0.9601\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.2955 - acc: 0.9541\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2586 - acc: 0.9761\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.2449 - acc: 0.9806\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.2458 - acc: 0.9750\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.2379 - acc: 0.9780\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.2286 - acc: 0.9803\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.2224 - acc: 0.9812\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.2119 - acc: 0.9841\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.2109 - acc: 0.9826\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.2062 - acc: 0.9825\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1998 - acc: 0.9844\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1976 - acc: 0.9842\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.2007 - acc: 0.9822\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2009 - acc: 0.9814\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1934 - acc: 0.9834\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1850 - acc: 0.9840\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1798 - acc: 0.9866\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1772 - acc: 0.9861\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1833 - acc: 0.9828\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1842 - acc: 0.9832\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1732 - acc: 0.9853\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1655 - acc: 0.9873\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1693 - acc: 0.9870\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.1662 - acc: 0.9852\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1645 - acc: 0.9870\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1659 - acc: 0.9850\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1606 - acc: 0.9856\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1531 - acc: 0.9873\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1520 - acc: 0.9873\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1508 - acc: 0.9865\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1494 - acc: 0.9871\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1507 - acc: 0.9876\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1504 - acc: 0.9863\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1481 - acc: 0.9880\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1492 - acc: 0.9868\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1433 - acc: 0.9875\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1567 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1503 - acc: 0.9845\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1410 - acc: 0.9870\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1400 - acc: 0.9881\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1433 - acc: 0.9862\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1339 - acc: 0.9876\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.1350 - acc: 0.9874\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1395 - acc: 0.9868\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1345 - acc: 0.9877\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1339 - acc: 0.9879\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1462 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1406 - acc: 0.9860\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1340 - acc: 0.9859\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1307 - acc: 0.9872\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1288 - acc: 0.9882\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.1259 - acc: 0.9882\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1245 - acc: 0.9884\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1254 - acc: 0.9870\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1271 - acc: 0.9867\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1253 - acc: 0.9864\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1257 - acc: 0.9878\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.1223 - acc: 0.9881\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1219 - acc: 0.9870\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.1192 - acc: 0.9869\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1217 - acc: 0.9866\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1219 - acc: 0.9868\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1225 - acc: 0.9879\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1213 - acc: 0.9865\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.1202 - acc: 0.9877\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1215 - acc: 0.9871\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1185 - acc: 0.9860\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1151 - acc: 0.9880\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1174 - acc: 0.9878\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1138 - acc: 0.9887\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1139 - acc: 0.9877\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1197 - acc: 0.9855\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1214 - acc: 0.9865\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1200 - acc: 0.9861\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1192 - acc: 0.9862\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1164 - acc: 0.9871\n",
      "Training accuracy:0.9898999929428101\n",
      "Testing accuracy:0.41019999980926514\n",
      "Training accuracy:0.7441250085830688\n",
      "Validation accuracy:0.7441250085830688\n",
      "Testing accuracy:0.5200999975204468\n",
      "total time: 303.07876992225647\n",
      "tr30000\n",
      "trial 0\n",
      "60000\n",
      "(7017,)\n",
      "(7983,)\n",
      "(6912,)\n",
      "(8088,)\n",
      "(5458,)\n",
      "(4542,)\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 2s 83us/sample - loss: 1.3092 - acc: 0.7800\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 2s 62us/sample - loss: 0.9021 - acc: 0.7899\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 2s 72us/sample - loss: 0.7358 - acc: 0.7971\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.6472 - acc: 0.8016\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.5948 - acc: 0.8017\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.5547 - acc: 0.8053\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.5271 - acc: 0.8072\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.5077 - acc: 0.8083\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.4934 - acc: 0.8133\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.4779 - acc: 0.8151\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 2s 62us/sample - loss: 0.4656 - acc: 0.8198\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.4541 - acc: 0.8225\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 2s 60us/sample - loss: 0.4455 - acc: 0.8261\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.4371 - acc: 0.8296\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.4236 - acc: 0.8364\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 2s 62us/sample - loss: 0.4185 - acc: 0.8379\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.4136 - acc: 0.8419\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.4020 - acc: 0.8498\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.3969 - acc: 0.8505\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.3861 - acc: 0.8554\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.3744 - acc: 0.8625\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 2s 62us/sample - loss: 0.3737 - acc: 0.8623\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.3633 - acc: 0.8673\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.3544 - acc: 0.8736\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.3438 - acc: 0.8788\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.3403 - acc: 0.8802\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.3324 - acc: 0.8848\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.3250 - acc: 0.8885\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.3230 - acc: 0.8897\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.3149 - acc: 0.8932\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.3077 - acc: 0.8968\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.2900 - acc: 0.9074\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.2875 - acc: 0.9077\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.2842 - acc: 0.9111\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2810 - acc: 0.9119\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 2s 62us/sample - loss: 0.2750 - acc: 0.9151\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.2768 - acc: 0.9146\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.2611 - acc: 0.9218\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 2s 61us/sample - loss: 0.2648 - acc: 0.9191\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.2563 - acc: 0.9239\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.2508 - acc: 0.9266\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.2494 - acc: 0.9277\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2428 - acc: 0.9331\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.2402 - acc: 0.9327\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.2374 - acc: 0.9320\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.2360 - acc: 0.9339\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.2340 - acc: 0.9351\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.2333 - acc: 0.9361\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.2307 - acc: 0.9357\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.2309 - acc: 0.9374\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2291 - acc: 0.9362\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2210 - acc: 0.9399\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2206 - acc: 0.9400\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2192 - acc: 0.9412\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.2198 - acc: 0.9424\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 2s 71us/sample - loss: 0.2103 - acc: 0.9437\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 2s 72us/sample - loss: 0.2114 - acc: 0.9432\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.2111 - acc: 0.9455\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2210 - acc: 0.9385\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.2074 - acc: 0.9472\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.2075 - acc: 0.9456\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.2148 - acc: 0.9419\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.2112 - acc: 0.9441\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.2036 - acc: 0.9468\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.2019 - acc: 0.9475\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.2031 - acc: 0.9461\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.2082 - acc: 0.9450\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.2072 - acc: 0.9461\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1999 - acc: 0.9484\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.1947 - acc: 0.9483\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1943 - acc: 0.9514\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.1963 - acc: 0.9495\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1954 - acc: 0.9498\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 2s 60us/sample - loss: 0.2013 - acc: 0.9471\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 2s 59us/sample - loss: 0.2048 - acc: 0.9445\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1893 - acc: 0.9532\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.1948 - acc: 0.9493\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1909 - acc: 0.9523\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.1888 - acc: 0.9527\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 2s 72us/sample - loss: 0.1916 - acc: 0.9507\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.1982 - acc: 0.94741s - loss: 0.1\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1877 - acc: 0.9516\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1887 - acc: 0.9515\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.1891 - acc: 0.9510\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 2s 70us/sample - loss: 0.1864 - acc: 0.9524\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1894 - acc: 0.9515\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.1869 - acc: 0.9518\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 69us/sample - loss: 0.1828 - acc: 0.9532\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.1855 - acc: 0.9527\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.1848 - acc: 0.9524\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1829 - acc: 0.9539\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.1829 - acc: 0.9537\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1886 - acc: 0.9505\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1854 - acc: 0.9529\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 2s 73us/sample - loss: 0.1848 - acc: 0.9535\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1921 - acc: 0.9496\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.1820 - acc: 0.9539\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 2s 63us/sample - loss: 0.1834 - acc: 0.9522\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 2s 59us/sample - loss: 0.1807 - acc: 0.9531\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 2s 65us/sample - loss: 0.1813 - acc: 0.9528\n",
      "Training accuracy:0.9619333148002625\n",
      "Testing accuracy:0.4018999934196472\n",
      "Training accuracy:0.5887083411216736\n",
      "Validation accuracy:0.5887083411216736\n",
      "Testing accuracy:0.5393999814987183\n",
      "total time: 641.9483890533447\n",
      "tr60000\n",
      "trial 0\n",
      "60000\n",
      "(13964,)\n",
      "(16036,)\n",
      "(13720,)\n",
      "(16280,)\n",
      "(5431,)\n",
      "(4569,)\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 1.1078 - acc: 0.7804\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.6915 - acc: 0.7920\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.5780 - acc: 0.7946\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.5261 - acc: 0.7963\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4966 - acc: 0.7981\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4814 - acc: 0.7970\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4692 - acc: 0.8009\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4616 - acc: 0.8016\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4562 - acc: 0.8020\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4498 - acc: 0.8056\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4463 - acc: 0.8065\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4447 - acc: 0.8072\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4409 - acc: 0.8106\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4379 - acc: 0.8110\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4364 - acc: 0.8115\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4335 - acc: 0.8131\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4317 - acc: 0.8158\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4282 - acc: 0.8168\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4253 - acc: 0.8193\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4264 - acc: 0.8179\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4227 - acc: 0.8218\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4196 - acc: 0.8231\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4182 - acc: 0.8242\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4145 - acc: 0.8268\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4129 - acc: 0.8281\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4105 - acc: 0.8291\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4067 - acc: 0.8320\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4048 - acc: 0.8331\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4029 - acc: 0.8347\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.3985 - acc: 0.8368\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4005 - acc: 0.8363\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3942 - acc: 0.84021s - loss: \n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3937 - acc: 0.8404\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3911 - acc: 0.8408\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3863 - acc: 0.8444\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3840 - acc: 0.8458\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3860 - acc: 0.8461\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3789 - acc: 0.8496\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3775 - acc: 0.8489\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3752 - acc: 0.8511\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3727 - acc: 0.8531\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3713 - acc: 0.8528\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3666 - acc: 0.8567\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3654 - acc: 0.8568\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3636 - acc: 0.8583\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3613 - acc: 0.8591\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3593 - acc: 0.8600\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3566 - acc: 0.8617\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3514 - acc: 0.8657\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3511 - acc: 0.8651\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.3493 - acc: 0.8662\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3473 - acc: 0.8679\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3460 - acc: 0.8662\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3416 - acc: 0.8697\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3455 - acc: 0.8687\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3389 - acc: 0.8725\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3355 - acc: 0.8732\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3397 - acc: 0.8724\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3329 - acc: 0.8746\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3329 - acc: 0.8754\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3330 - acc: 0.8753\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3258 - acc: 0.8793\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3270 - acc: 0.8783\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3276 - acc: 0.8780\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3225 - acc: 0.8802\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3231 - acc: 0.8816\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3239 - acc: 0.8802\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3217 - acc: 0.88130s - loss: 0.3201 - acc:\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3171 - acc: 0.8827\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3197 - acc: 0.8822\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3140 - acc: 0.8854\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3156 - acc: 0.8853\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3139 - acc: 0.8863\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3125 - acc: 0.8866\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3115 - acc: 0.8871\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3093 - acc: 0.8880\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3102 - acc: 0.8875\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3038 - acc: 0.8907\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3086 - acc: 0.8881\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3092 - acc: 0.8876\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3078 - acc: 0.8903\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3002 - acc: 0.8926\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3015 - acc: 0.8923\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3002 - acc: 0.8919\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3001 - acc: 0.8930\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2970 - acc: 0.8936\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2987 - acc: 0.8933\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2968 - acc: 0.8945\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2991 - acc: 0.8936\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2972 - acc: 0.8941\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2967 - acc: 0.8950\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2954 - acc: 0.8958\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2993 - acc: 0.8925\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2937 - acc: 0.8961\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2904 - acc: 0.8971\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2913 - acc: 0.8977\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2940 - acc: 0.8965\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2891 - acc: 0.8986\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2918 - acc: 0.8965\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2891 - acc: 0.8983\n",
      "Training accuracy:0.9000999927520752\n",
      "Testing accuracy:0.39579999446868896\n",
      "Training accuracy:0.5287708044052124\n",
      "Validation accuracy:0.5287708044052124\n",
      "Testing accuracy:0.703000009059906\n",
      "total time: 1244.8572309017181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_trial =10\n",
    "n_tr_list = [ 1000,5000, 10000, 30000, 60000] # list of training sample sizes\n",
    "\n",
    "k=0\n",
    "K = len(n_tr_list)\n",
    "ERM_model_acc = np.zeros((K,n_trial))\n",
    "ERM_model_acc_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc = np.zeros((K,n_trial))\n",
    "IRM_model_acc_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc1 = np.zeros((K,n_trial))\n",
    "ERM_model_acc1_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc1 = np.zeros((K,n_trial))\n",
    "IRM_model_acc1_v = np.zeros((K,n_trial))\n",
    "IRM_model_ind_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc_av = np.zeros(K)\n",
    "ERM_model_acc_av_nb = np.zeros(K)\n",
    "IRM_model_acc_av = np.zeros(K)\n",
    "IRM_model_acc_av_v = np.zeros(K)\n",
    "\n",
    "\n",
    "ERM_model_acc_av1 = np.zeros(K)\n",
    "ERM_model_acc_av1_nb = np.zeros(K)\n",
    "IRM_model_acc_av1 = np.zeros(K)\n",
    "IRM_model_acc_av1_v = np.zeros(K)\n",
    "\n",
    "list_params = []\n",
    "for n_tr in n_tr_list:\n",
    "    print (\"tr\" + str(n_tr))\n",
    "#     print (\"start\")\n",
    "    t_start = time.time()\n",
    "    for trial in range(n_trial):\n",
    "        print (\"trial \" + str(trial))\n",
    "        n_e=2\n",
    "        p_color_list = [0.2, 0.1]\n",
    "        p_label_list = [0.25]*n_e\n",
    "        D = assemble_data_mnist_confounded_child(n_tr) # initialize mnist digits data object\n",
    "\n",
    "        D.create_training_data(n_e, p_color_list, p_label_list) # creates the training environments\n",
    "\n",
    "        p_label_test = 0.25 # probability of switching pre-label in test environment\n",
    "        p_color_test = 0.9  # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "        D.create_testing_data(p_color_test, p_label_test, n_e)  # sets up the testing environment\n",
    "        (num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "        num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data\n",
    "\n",
    "        model_erm =  keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        num_epochs = 100\n",
    "        batch_size = 512\n",
    "        learning_rate = 4.9e-4\n",
    "        erm_model1 = standard_erm_model(model_erm, num_epochs, batch_size, learning_rate)\n",
    "        erm_model1.fit(D.data_tuple_list)\n",
    "        erm_model1.evaluate(D.data_tuple_test)\n",
    "        print (\"Training accuracy:\" + str(erm_model1.train_acc))\n",
    "        print (\"Testing accuracy:\" + str(erm_model1.test_acc))\n",
    "        \n",
    "        ERM_model_acc[k][trial] = erm_model1.test_acc\n",
    "        ERM_model_acc1[k][trial] = erm_model1.train_acc\n",
    "\n",
    "\n",
    "#         gamma_list = [10000, 33000, 66000,100000.0]\n",
    "        gamma_list = [100000]\n",
    "        index=0\n",
    "        best_err = 1e6\n",
    "        train_list =[]\n",
    "        val_list = []\n",
    "        test_list = []\n",
    "        for gamma_new in gamma_list:\n",
    "\n",
    "            model_irm = keras.Sequential([\n",
    "                                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(num_classes)\n",
    "                        ])\n",
    "            batch_size       = 512\n",
    "            steps_max        = 1000\n",
    "            steps_threshold  = 190  ## threshold after which gamma_new is used\n",
    "            learning_rate    = 4.9e-4\n",
    "\n",
    "\n",
    "            irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "            irm_model1.fit(D.data_tuple_list)\n",
    "            irm_model1.evaluate(D.data_tuple_test)\n",
    "            error_val = 1-irm_model1.val_acc\n",
    "            train_list.append(irm_model1.train_acc)\n",
    "            val_list.append(irm_model1.val_acc)\n",
    "            test_list.append(irm_model1.test_acc)\n",
    "            if(error_val<best_err):\n",
    "                index_best =index\n",
    "                best_err = error_val\n",
    "            index= index+1\n",
    "\n",
    "        print (\"Training accuracy:\" + str(train_list[index_best]))\n",
    "        print (\"Validation accuracy:\" + str(val_list[index_best]))\n",
    "        print (\"Testing accuracy:\" + str(test_list[index_best]))\n",
    "\n",
    "        IRM_model_acc_v[k][trial]  = test_list[index_best]\n",
    "        IRM_model_acc1_v[k][trial] = train_list[index_best]\n",
    "        IRM_model_ind_v[k][trial]  = index_best\n",
    "\n",
    "\n",
    "    IRM_model_acc_av_v[k] = np.mean(IRM_model_acc_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_test\", np.mean(IRM_model_acc_v[k]),np.std(IRM_model_acc_v[k])])\n",
    "\n",
    "    ERM_model_acc_av[k] = np.mean(ERM_model_acc[k])\n",
    "    list_params.append([n_tr,\"ERM_test\", np.mean(ERM_model_acc[k]),np.std(ERM_model_acc[k])])\n",
    "\n",
    "\n",
    "    IRM_model_acc_av1_v[k] = np.mean(IRM_model_acc1_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_train\", np.mean(IRM_model_acc1_v[k]),np.std(IRM_model_acc1_v[k])])\n",
    "    \n",
    "    ERM_model_acc_av1[k] = np.mean(ERM_model_acc1[k])\n",
    "    list_params.append([n_tr, \"ERM_train\", np.mean(ERM_model_acc1[k]),np.std(ERM_model_acc1[k])])\n",
    "\n",
    "\n",
    "    k=k+1\n",
    "\n",
    "    t_end = time.time()\n",
    "    print(\"total time: \" + str(t_end-t_start))\n",
    "results = pd.DataFrame(list_params, columns= [\"Sample\",\"Method\", \"Performance\", \"Sdev\"])\n",
    "ideal_error = np.ones(5)*0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01, 0.8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of samples\", fontsize=16)\n",
    "plt.ylabel(\"Test error\", fontsize=16)\n",
    "plt.plot(n_tr_list, 1-ERM_model_acc_av, \"-r\", marker=\"+\", label=\"ERM\")\n",
    "plt.plot(n_tr_list, 1-IRM_model_acc_av_v, \"-b\", marker=\"s\",label=\"IRMv1\")\n",
    "plt.plot(n_tr_list, ideal_error, \"-g\", marker=\"x\", label=\"Optimal invariant\")\n",
    "plt.legend(loc=\"upper left\", fontsize=18)\n",
    "plt.ylim(-0.01,0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
