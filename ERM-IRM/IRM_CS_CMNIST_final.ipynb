{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to run this notebook\n",
    "\n",
    "In this notebook, we present the comparisons for CS-MNIST: Covaraite shift based colored MNIST.. \n",
    "Run all the cells sequentially from top to bottom; we have commented the cells to help the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import cProfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_construct import * ## contains functions for constructing data \n",
    "from IRM_methods import *    ## contains IRM and ERM methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample complexity on CS-CMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr1000\n",
      "trial 0\n",
      "WARNING:tensorflow:From /Users/kartikahuja/Desktop/Python_codes/aif360v1.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "533/533 [==============================] - 0s 839us/sample - loss: 1.8487 - acc: 0.5291\n",
      "Epoch 2/100\n",
      "533/533 [==============================] - 0s 51us/sample - loss: 1.5220 - acc: 0.8649\n",
      "Epoch 3/100\n",
      "533/533 [==============================] - 0s 59us/sample - loss: 1.5198 - acc: 0.8649\n",
      "Epoch 4/100\n",
      "533/533 [==============================] - 0s 51us/sample - loss: 1.5119 - acc: 0.8649\n",
      "Epoch 5/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 1.4440 - acc: 0.8649\n",
      "Epoch 6/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 1.3561 - acc: 0.8649\n",
      "Epoch 7/100\n",
      "533/533 [==============================] - 0s 67us/sample - loss: 1.2892 - acc: 0.8649\n",
      "Epoch 8/100\n",
      "533/533 [==============================] - 0s 74us/sample - loss: 1.2442 - acc: 0.8743\n",
      "Epoch 9/100\n",
      "533/533 [==============================] - 0s 65us/sample - loss: 1.2058 - acc: 0.8874\n",
      "Epoch 10/100\n",
      "533/533 [==============================] - 0s 60us/sample - loss: 1.1641 - acc: 0.8893\n",
      "Epoch 11/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 1.1251 - acc: 0.8874\n",
      "Epoch 12/100\n",
      "533/533 [==============================] - 0s 59us/sample - loss: 1.0967 - acc: 0.8818\n",
      "Epoch 13/100\n",
      "533/533 [==============================] - 0s 68us/sample - loss: 1.0642 - acc: 0.8856\n",
      "Epoch 14/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 1.0218 - acc: 0.9043\n",
      "Epoch 15/100\n",
      "533/533 [==============================] - 0s 65us/sample - loss: 0.9852 - acc: 0.9250\n",
      "Epoch 16/100\n",
      "533/533 [==============================] - 0s 60us/sample - loss: 0.9620 - acc: 0.9493\n",
      "Epoch 17/100\n",
      "533/533 [==============================] - 0s 62us/sample - loss: 0.9357 - acc: 0.9531\n",
      "Epoch 18/100\n",
      "533/533 [==============================] - 0s 69us/sample - loss: 0.9036 - acc: 0.9456\n",
      "Epoch 19/100\n",
      "533/533 [==============================] - 0s 66us/sample - loss: 0.8767 - acc: 0.9493\n",
      "Epoch 20/100\n",
      "533/533 [==============================] - 0s 60us/sample - loss: 0.8519 - acc: 0.9550\n",
      "Epoch 21/100\n",
      "533/533 [==============================] - 0s 62us/sample - loss: 0.8270 - acc: 0.9568\n",
      "Epoch 22/100\n",
      "533/533 [==============================] - 0s 78us/sample - loss: 0.7976 - acc: 0.9606\n",
      "Epoch 23/100\n",
      "533/533 [==============================] - 0s 71us/sample - loss: 0.7702 - acc: 0.9681\n",
      "Epoch 24/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 0.7503 - acc: 0.9719\n",
      "Epoch 25/100\n",
      "533/533 [==============================] - 0s 59us/sample - loss: 0.7277 - acc: 0.9719\n",
      "Epoch 26/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 0.7122 - acc: 0.9719\n",
      "Epoch 27/100\n",
      "533/533 [==============================] - 0s 64us/sample - loss: 0.7045 - acc: 0.9756\n",
      "Epoch 28/100\n",
      "533/533 [==============================] - 0s 71us/sample - loss: 0.6890 - acc: 0.9756\n",
      "Epoch 29/100\n",
      "533/533 [==============================] - 0s 51us/sample - loss: 0.6582 - acc: 0.9794\n",
      "Epoch 30/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.6396 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.6266 - acc: 0.9850\n",
      "Epoch 32/100\n",
      "533/533 [==============================] - 0s 50us/sample - loss: 0.6109 - acc: 0.9869\n",
      "Epoch 33/100\n",
      "533/533 [==============================] - 0s 48us/sample - loss: 0.6045 - acc: 0.9850\n",
      "Epoch 34/100\n",
      "533/533 [==============================] - 0s 50us/sample - loss: 0.5947 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "533/533 [==============================] - 0s 64us/sample - loss: 0.5790 - acc: 0.9850\n",
      "Epoch 36/100\n",
      "533/533 [==============================] - 0s 56us/sample - loss: 0.5685 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 0.5553 - acc: 0.9906\n",
      "Epoch 38/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.5598 - acc: 0.9944\n",
      "Epoch 39/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.5465 - acc: 0.9944\n",
      "Epoch 40/100\n",
      "533/533 [==============================] - 0s 62us/sample - loss: 0.5308 - acc: 0.9906\n",
      "Epoch 41/100\n",
      "533/533 [==============================] - 0s 62us/sample - loss: 0.5239 - acc: 0.9869\n",
      "Epoch 42/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.5105 - acc: 0.9925\n",
      "Epoch 43/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.5015 - acc: 0.9944\n",
      "Epoch 44/100\n",
      "533/533 [==============================] - 0s 73us/sample - loss: 0.4940 - acc: 0.9962\n",
      "Epoch 45/100\n",
      "533/533 [==============================] - 0s 65us/sample - loss: 0.4845 - acc: 0.9962\n",
      "Epoch 46/100\n",
      "533/533 [==============================] - 0s 59us/sample - loss: 0.4792 - acc: 0.9925\n",
      "Epoch 47/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 0.4735 - acc: 0.9944\n",
      "Epoch 48/100\n",
      "533/533 [==============================] - 0s 55us/sample - loss: 0.4665 - acc: 0.9962\n",
      "Epoch 49/100\n",
      "533/533 [==============================] - 0s 50us/sample - loss: 0.4554 - acc: 0.9981\n",
      "Epoch 50/100\n",
      "533/533 [==============================] - 0s 66us/sample - loss: 0.4488 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "533/533 [==============================] - 0s 60us/sample - loss: 0.4463 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 0.4384 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.4333 - acc: 0.9981\n",
      "Epoch 54/100\n",
      "533/533 [==============================] - 0s 60us/sample - loss: 0.4329 - acc: 0.9981\n",
      "Epoch 55/100\n",
      "533/533 [==============================] - 0s 67us/sample - loss: 0.4279 - acc: 0.9981\n",
      "Epoch 56/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 0.4189 - acc: 0.9981\n",
      "Epoch 57/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.4127 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "533/533 [==============================] - 0s 68us/sample - loss: 0.4093 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.4043 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 0.3995 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "533/533 [==============================] - 0s 50us/sample - loss: 0.3952 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3913 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "533/533 [==============================] - 0s 53us/sample - loss: 0.3877 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "533/533 [==============================] - 0s 69us/sample - loss: 0.3840 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3802 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "533/533 [==============================] - 0s 59us/sample - loss: 0.3762 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "533/533 [==============================] - 0s 65us/sample - loss: 0.3729 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3703 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "533/533 [==============================] - 0s 55us/sample - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3627 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 0.3585 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "533/533 [==============================] - 0s 69us/sample - loss: 0.3563 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.3542 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "533/533 [==============================] - 0s 46us/sample - loss: 0.3505 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "533/533 [==============================] - 0s 51us/sample - loss: 0.3462 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 0.3425 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "533/533 [==============================] - 0s 56us/sample - loss: 0.3392 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.3360 - acc: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 0s 55us/sample - loss: 0.3330 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "533/533 [==============================] - 0s 56us/sample - loss: 0.3300 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 0.3269 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 0.3239 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3208 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "533/533 [==============================] - 0s 61us/sample - loss: 0.3180 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "533/533 [==============================] - 0s 56us/sample - loss: 0.3155 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "533/533 [==============================] - 0s 52us/sample - loss: 0.3128 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "533/533 [==============================] - 0s 50us/sample - loss: 0.3097 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "533/533 [==============================] - 0s 57us/sample - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "533/533 [==============================] - 0s 62us/sample - loss: 0.3024 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "533/533 [==============================] - 0s 53us/sample - loss: 0.2993 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 0.2963 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "533/533 [==============================] - 0s 45us/sample - loss: 0.2937 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "533/533 [==============================] - 0s 63us/sample - loss: 0.2914 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "533/533 [==============================] - 0s 54us/sample - loss: 0.2891 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "533/533 [==============================] - 0s 55us/sample - loss: 0.2865 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "533/533 [==============================] - 0s 51us/sample - loss: 0.2839 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "533/533 [==============================] - 0s 58us/sample - loss: 0.2813 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "533/533 [==============================] - 0s 53us/sample - loss: 0.2790 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "533/533 [==============================] - 0s 49us/sample - loss: 0.2768 - acc: 1.0000\n",
      "Training accuracy:1.0\n",
      "Testing accuracy:0.46047550439834595\n",
      "Training accuracy:1.0\n",
      "Validation accuracy:1.0\n",
      "Testing accuracy:0.5326153039932251\n",
      "total time: 543.9733607769012\n",
      "tr5000\n",
      "trial 0\n",
      "Epoch 1/100\n",
      "2507/2507 [==============================] - 1s 330us/sample - loss: 1.6270 - acc: 0.7734\n",
      "Epoch 2/100\n",
      "2507/2507 [==============================] - 0s 42us/sample - loss: 1.4176 - acc: 0.8636\n",
      "Epoch 3/100\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 1.2895 - acc: 0.8827\n",
      "Epoch 4/100\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 1.1741 - acc: 0.8887\n",
      "Epoch 5/100\n",
      "2507/2507 [==============================] - 0s 49us/sample - loss: 1.0774 - acc: 0.9114\n",
      "Epoch 6/100\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.9866 - acc: 0.9238\n",
      "Epoch 7/100\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.9060 - acc: 0.9306\n",
      "Epoch 8/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.8341 - acc: 0.9473\n",
      "Epoch 9/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.7689 - acc: 0.9533\n",
      "Epoch 10/100\n",
      "2507/2507 [==============================] - 0s 49us/sample - loss: 0.7128 - acc: 0.9617\n",
      "Epoch 11/100\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.6611 - acc: 0.9677\n",
      "Epoch 12/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.6133 - acc: 0.9717\n",
      "Epoch 13/100\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.5717 - acc: 0.9801\n",
      "Epoch 14/100\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.5358 - acc: 0.9836\n",
      "Epoch 15/100\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.5045 - acc: 0.9896\n",
      "Epoch 16/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.4761 - acc: 0.9896\n",
      "Epoch 17/100\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.4484 - acc: 0.9948\n",
      "Epoch 18/100\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.4253 - acc: 0.9976\n",
      "Epoch 19/100\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.4044 - acc: 0.9968\n",
      "Epoch 20/100\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.3847 - acc: 0.9980\n",
      "Epoch 21/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.3678 - acc: 0.9992\n",
      "Epoch 22/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.3522 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.3386 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.3255 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.3129 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.3012 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.2904 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.2801 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.2700 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.2606 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.2517 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.2433 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.2356 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.2274 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.2198 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.2127 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "2507/2507 [==============================] - 0s 73us/sample - loss: 0.2059 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.1996 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.1874 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.1817 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.1761 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.1707 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.1654 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.1555 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.1465 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.1422 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.1342 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "2507/2507 [==============================] - 0s 49us/sample - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.1234 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.1168 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.1138 - acc: 1.0000\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.1104 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.1073 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.1045 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.1017 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "2507/2507 [==============================] - 0s 47us/sample - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0964 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "2507/2507 [==============================] - 0s 49us/sample - loss: 0.0939 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0914 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "2507/2507 [==============================] - 0s 48us/sample - loss: 0.0891 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0870 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0828 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "2507/2507 [==============================] - 0s 48us/sample - loss: 0.0697 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0649 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0637 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0593 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0499 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "2507/2507 [==============================] - 0s 49us/sample - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0453 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0428 - acc: 1.0000\n",
      "Training accuracy:1.0\n",
      "Testing accuracy:0.7621926665306091\n",
      "Training accuracy:1.0\n",
      "Validation accuracy:1.0\n",
      "Testing accuracy:0.7902055382728577\n",
      "total time: 813.2957570552826\n",
      "tr10000\n",
      "trial 0\n",
      "Epoch 1/100\n",
      "4961/4961 [==============================] - 1s 218us/sample - loss: 1.5259 - acc: 0.8148\n",
      "Epoch 2/100\n",
      "4961/4961 [==============================] - 0s 61us/sample - loss: 1.2414 - acc: 0.8764\n",
      "Epoch 3/100\n",
      "4961/4961 [==============================] - 0s 48us/sample - loss: 1.0456 - acc: 0.9097\n",
      "Epoch 4/100\n",
      "4961/4961 [==============================] - 0s 53us/sample - loss: 0.8983 - acc: 0.9214\n",
      "Epoch 5/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.7761 - acc: 0.9369\n",
      "Epoch 6/100\n",
      "4961/4961 [==============================] - 0s 44us/sample - loss: 0.6797 - acc: 0.9528\n",
      "Epoch 7/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.6048 - acc: 0.9611\n",
      "Epoch 8/100\n",
      "4961/4961 [==============================] - 0s 50us/sample - loss: 0.5369 - acc: 0.9730\n",
      "Epoch 9/100\n",
      "4961/4961 [==============================] - 0s 68us/sample - loss: 0.4849 - acc: 0.9798\n",
      "Epoch 10/100\n",
      "4961/4961 [==============================] - 0s 61us/sample - loss: 0.4409 - acc: 0.9845\n",
      "Epoch 11/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.4027 - acc: 0.9909\n",
      "Epoch 12/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.3706 - acc: 0.9935\n",
      "Epoch 13/100\n",
      "4961/4961 [==============================] - 0s 57us/sample - loss: 0.3449 - acc: 0.9946\n",
      "Epoch 14/100\n",
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.3216 - acc: 0.9980\n",
      "Epoch 15/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.2990 - acc: 0.9992\n",
      "Epoch 16/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.2811 - acc: 0.9996\n",
      "Epoch 17/100\n",
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.2629 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "4961/4961 [==============================] - 0s 53us/sample - loss: 0.2482 - acc: 0.9996\n",
      "Epoch 19/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.2342 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "4961/4961 [==============================] - 0s 53us/sample - loss: 0.2212 - acc: 0.9998\n",
      "Epoch 21/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.2088 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.1979 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.1882 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.1785 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.1697 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.1529 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "4961/4961 [==============================] - 0s 62us/sample - loss: 0.1452 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.1384 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.1317 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "4961/4961 [==============================] - 0s 49us/sample - loss: 0.1256 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.1199 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "4961/4961 [==============================] - 0s 63us/sample - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.1050 - acc: 1.0000\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0962 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "4961/4961 [==============================] - 0s 63us/sample - loss: 0.0921 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "4961/4961 [==============================] - 0s 57us/sample - loss: 0.0882 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "4961/4961 [==============================] - 0s 63us/sample - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "4961/4961 [==============================] - 0s 70us/sample - loss: 0.0811 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "4961/4961 [==============================] - 0s 66us/sample - loss: 0.0750 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.0692 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "4961/4961 [==============================] - 0s 70us/sample - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "4961/4961 [==============================] - 0s 57us/sample - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "4961/4961 [==============================] - 0s 62us/sample - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "4961/4961 [==============================] - 0s 68us/sample - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "4961/4961 [==============================] - 0s 61us/sample - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "4961/4961 [==============================] - 0s 62us/sample - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "4961/4961 [==============================] - 0s 67us/sample - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "4961/4961 [==============================] - 0s 61us/sample - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "4961/4961 [==============================] - 0s 65us/sample - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "4961/4961 [==============================] - 0s 67us/sample - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "4961/4961 [==============================] - 0s 68us/sample - loss: 0.0413 - acc: 0.9998\n",
      "Epoch 63/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "4961/4961 [==============================] - 0s 53us/sample - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "4961/4961 [==============================] - 0s 72us/sample - loss: 0.0406 - acc: 0.9998\n",
      "Epoch 66/100\n",
      "4961/4961 [==============================] - 0s 57us/sample - loss: 0.0390 - acc: 0.9998\n",
      "Epoch 67/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.0381 - acc: 0.9998\n",
      "Epoch 68/100\n",
      "4961/4961 [==============================] - 0s 54us/sample - loss: 0.0381 - acc: 0.9998\n",
      "Epoch 69/100\n",
      "4961/4961 [==============================] - 0s 73us/sample - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "4961/4961 [==============================] - 0s 65us/sample - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "4961/4961 [==============================] - 0s 62us/sample - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "4961/4961 [==============================] - 0s 55us/sample - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "4961/4961 [==============================] - 0s 65us/sample - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "4961/4961 [==============================] - 0s 69us/sample - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "4961/4961 [==============================] - 0s 51us/sample - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "4961/4961 [==============================] - 0s 61us/sample - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "4961/4961 [==============================] - 0s 58us/sample - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "4961/4961 [==============================] - 0s 73us/sample - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "4961/4961 [==============================] - 0s 65us/sample - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "4961/4961 [==============================] - 0s 64us/sample - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "4961/4961 [==============================] - 0s 80us/sample - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "4961/4961 [==============================] - 0s 76us/sample - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "4961/4961 [==============================] - 0s 67us/sample - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "4961/4961 [==============================] - 0s 62us/sample - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "4961/4961 [==============================] - 0s 60us/sample - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "4961/4961 [==============================] - 0s 54us/sample - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "4961/4961 [==============================] - 0s 65us/sample - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "4961/4961 [==============================] - 0s 82us/sample - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "4961/4961 [==============================] - 0s 79us/sample - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "4961/4961 [==============================] - 0s 56us/sample - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "4961/4961 [==============================] - 0s 59us/sample - loss: 0.0202 - acc: 1.0000\n",
      "Training accuracy:1.0\n",
      "Testing accuracy:0.8384507298469543\n",
      "Training accuracy:1.0\n",
      "Validation accuracy:1.0\n",
      "Testing accuracy:0.8569135069847107\n",
      "total time: 1104.055879831314\n",
      "tr30000\n",
      "trial 0\n",
      "Epoch 1/100\n",
      "15122/15122 [==============================] - 2s 153us/sample - loss: 1.3085 - acc: 0.8511\n",
      "Epoch 2/100\n",
      "15122/15122 [==============================] - 1s 73us/sample - loss: 0.8308 - acc: 0.9272\n",
      "Epoch 3/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.5984 - acc: 0.9524\n",
      "Epoch 4/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.4695 - acc: 0.9683\n",
      "Epoch 5/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.3862 - acc: 0.9773\n",
      "Epoch 6/100\n",
      "15122/15122 [==============================] - 1s 70us/sample - loss: 0.3271 - acc: 0.9813\n",
      "Epoch 7/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.2843 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "15122/15122 [==============================] - 1s 72us/sample - loss: 0.2505 - acc: 0.9860\n",
      "Epoch 9/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.2159 - acc: 0.9909\n",
      "Epoch 10/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.1902 - acc: 0.9936\n",
      "Epoch 11/100\n",
      "15122/15122 [==============================] - 1s 75us/sample - loss: 0.1727 - acc: 0.9942\n",
      "Epoch 12/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.1524 - acc: 0.9970\n",
      "Epoch 13/100\n",
      "15122/15122 [==============================] - 1s 72us/sample - loss: 0.1383 - acc: 0.9976\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.1257 - acc: 0.9977\n",
      "Epoch 15/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.1150 - acc: 0.9987\n",
      "Epoch 16/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.1055 - acc: 0.9989\n",
      "Epoch 17/100\n",
      "15122/15122 [==============================] - 1s 75us/sample - loss: 0.0965 - acc: 0.9993\n",
      "Epoch 18/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0893 - acc: 0.9992\n",
      "Epoch 19/100\n",
      "15122/15122 [==============================] - 1s 74us/sample - loss: 0.0840 - acc: 0.9989\n",
      "Epoch 20/100\n",
      "15122/15122 [==============================] - 1s 72us/sample - loss: 0.0792 - acc: 0.9991\n",
      "Epoch 21/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.0729 - acc: 0.9994\n",
      "Epoch 22/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.0680 - acc: 0.9998\n",
      "Epoch 23/100\n",
      "15122/15122 [==============================] - 1s 86us/sample - loss: 0.0644 - acc: 0.9998\n",
      "Epoch 24/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0604 - acc: 0.9996\n",
      "Epoch 25/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.0582 - acc: 0.99950s - loss: 0.0582 - acc: 0.9\n",
      "Epoch 26/100\n",
      "15122/15122 [==============================] - 1s 71us/sample - loss: 0.0592 - acc: 0.9976\n",
      "Epoch 27/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0572 - acc: 0.9983\n",
      "Epoch 28/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0506 - acc: 0.9996\n",
      "Epoch 29/100\n",
      "15122/15122 [==============================] - 1s 86us/sample - loss: 0.0473 - acc: 0.9999\n",
      "Epoch 30/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.0456 - acc: 0.9998\n",
      "Epoch 31/100\n",
      "15122/15122 [==============================] - 1s 71us/sample - loss: 0.0467 - acc: 0.9991\n",
      "Epoch 32/100\n",
      "15122/15122 [==============================] - 1s 87us/sample - loss: 0.0450 - acc: 0.9991\n",
      "Epoch 33/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0426 - acc: 0.9995\n",
      "Epoch 34/100\n",
      "15122/15122 [==============================] - 1s 84us/sample - loss: 0.0399 - acc: 0.9998\n",
      "Epoch 35/100\n",
      "15122/15122 [==============================] - 1s 75us/sample - loss: 0.0402 - acc: 0.9995\n",
      "Epoch 36/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.0405 - acc: 0.9985\n",
      "Epoch 37/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0376 - acc: 0.9995\n",
      "Epoch 38/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0374 - acc: 0.9993\n",
      "Epoch 39/100\n",
      "15122/15122 [==============================] - 1s 81us/sample - loss: 0.0348 - acc: 0.9997\n",
      "Epoch 40/100\n",
      "15122/15122 [==============================] - 1s 87us/sample - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0320 - acc: 0.9999\n",
      "Epoch 43/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0340 - acc: 0.9993\n",
      "Epoch 44/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0355 - acc: 0.9987\n",
      "Epoch 45/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0335 - acc: 0.9995\n",
      "Epoch 46/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0319 - acc: 0.9997\n",
      "Epoch 47/100\n",
      "15122/15122 [==============================] - 1s 81us/sample - loss: 0.0314 - acc: 0.9995\n",
      "Epoch 48/100\n",
      "15122/15122 [==============================] - 1s 86us/sample - loss: 0.0293 - acc: 0.9998\n",
      "Epoch 49/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0283 - acc: 0.9999\n",
      "Epoch 50/100\n",
      "15122/15122 [==============================] - 1s 84us/sample - loss: 0.0270 - acc: 0.9999\n",
      "Epoch 51/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0270 - acc: 0.9999\n",
      "Epoch 52/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0298 - acc: 0.9986\n",
      "Epoch 53/100\n",
      "15122/15122 [==============================] - 1s 86us/sample - loss: 0.0297 - acc: 0.9987\n",
      "Epoch 54/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0268 - acc: 0.9998\n",
      "Epoch 55/100\n",
      "15122/15122 [==============================] - 1s 84us/sample - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "15122/15122 [==============================] - 1s 85us/sample - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "15122/15122 [==============================] - 1s 84us/sample - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "15122/15122 [==============================] - 1s 86us/sample - loss: 0.0244 - acc: 0.9994\n",
      "Epoch 62/100\n",
      "15122/15122 [==============================] - 1s 85us/sample - loss: 0.0258 - acc: 0.9989\n",
      "Epoch 63/100\n",
      "15122/15122 [==============================] - 1s 89us/sample - loss: 0.0399 - acc: 0.9934\n",
      "Epoch 64/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0521 - acc: 0.9902\n",
      "Epoch 65/100\n",
      "15122/15122 [==============================] - 1s 81us/sample - loss: 0.0392 - acc: 0.9968\n",
      "Epoch 66/100\n",
      "15122/15122 [==============================] - 1s 84us/sample - loss: 0.0331 - acc: 0.9988\n",
      "Epoch 67/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0275 - acc: 0.9999\n",
      "Epoch 68/100\n",
      "15122/15122 [==============================] - 1s 85us/sample - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "15122/15122 [==============================] - 1s 85us/sample - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "15122/15122 [==============================] - 1s 87us/sample - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "15122/15122 [==============================] - 1s 82us/sample - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "15122/15122 [==============================] - 1s 82us/sample - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "15122/15122 [==============================] - 1s 83us/sample - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "15122/15122 [==============================] - 1s 88us/sample - loss: 0.0192 - acc: 1.00000s - loss: 0.0193 - \n",
      "Epoch 78/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "15122/15122 [==============================] - 1s 89us/sample - loss: 0.0191 - acc: 0.9999\n",
      "Epoch 80/100\n",
      "15122/15122 [==============================] - 1s 82us/sample - loss: 0.0203 - acc: 0.9999\n",
      "Epoch 81/100\n",
      "15122/15122 [==============================] - 1s 91us/sample - loss: 0.0199 - acc: 0.9998\n",
      "Epoch 82/100\n",
      "15122/15122 [==============================] - 1s 82us/sample - loss: 0.0196 - acc: 0.9999\n",
      "Epoch 83/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "15122/15122 [==============================] - 1s 73us/sample - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "15122/15122 [==============================] - 1s 75us/sample - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "15122/15122 [==============================] - 1s 74us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "15122/15122 [==============================] - 1s 72us/sample - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "15122/15122 [==============================] - 1s 78us/sample - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "15122/15122 [==============================] - 1s 75us/sample - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15122/15122 [==============================] - 1s 74us/sample - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "15122/15122 [==============================] - 1s 79us/sample - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0174 - acc: 0.9999\n",
      "Epoch 95/100\n",
      "15122/15122 [==============================] - 1s 76us/sample - loss: 0.0185 - acc: 0.9999\n",
      "Epoch 96/100\n",
      "15122/15122 [==============================] - 1s 77us/sample - loss: 0.0207 - acc: 0.9987\n",
      "Epoch 97/100\n",
      "15122/15122 [==============================] - 1s 80us/sample - loss: 0.0340 - acc: 0.9940\n",
      "Epoch 98/100\n",
      "15122/15122 [==============================] - 1s 73us/sample - loss: 0.0388 - acc: 0.9931\n",
      "Epoch 99/100\n",
      "15122/15122 [==============================] - 1s 81us/sample - loss: 0.0402 - acc: 0.9935\n",
      "Epoch 100/100\n",
      "15122/15122 [==============================] - 1s 70us/sample - loss: 0.0328 - acc: 0.9968\n",
      "Training accuracy:0.9990742206573486\n",
      "Testing accuracy:0.9089260697364807\n",
      "Training accuracy:0.990906834602356\n",
      "Validation accuracy:0.990906834602356\n",
      "Testing accuracy:0.8950231671333313\n",
      "total time: 1566.2765560150146\n",
      "tr60000\n",
      "trial 0\n",
      "Epoch 1/100\n",
      "30165/30165 [==============================] - 3s 83us/sample - loss: 1.0589 - acc: 0.8929\n",
      "Epoch 2/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.5350 - acc: 0.9549\n",
      "Epoch 3/100\n",
      "30165/30165 [==============================] - 1s 50us/sample - loss: 0.3661 - acc: 0.9710\n",
      "Epoch 4/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.2771 - acc: 0.9787\n",
      "Epoch 5/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.2189 - acc: 0.9836\n",
      "Epoch 6/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.1799 - acc: 0.9865\n",
      "Epoch 7/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.1489 - acc: 0.9896\n",
      "Epoch 8/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.1274 - acc: 0.9915\n",
      "Epoch 9/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.1108 - acc: 0.9932\n",
      "Epoch 10/100\n",
      "30165/30165 [==============================] - 1s 49us/sample - loss: 0.1006 - acc: 0.9930\n",
      "Epoch 11/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0874 - acc: 0.9953\n",
      "Epoch 12/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0783 - acc: 0.9965\n",
      "Epoch 13/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0729 - acc: 0.99631s - loss: 0.071\n",
      "Epoch 14/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0665 - acc: 0.9972\n",
      "Epoch 15/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0616 - acc: 0.9978\n",
      "Epoch 16/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0574 - acc: 0.9983\n",
      "Epoch 17/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0548 - acc: 0.9981\n",
      "Epoch 18/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.0497 - acc: 0.9991\n",
      "Epoch 19/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0499 - acc: 0.9978\n",
      "Epoch 20/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0482 - acc: 0.9982\n",
      "Epoch 21/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.0440 - acc: 0.9989\n",
      "Epoch 22/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0441 - acc: 0.9978\n",
      "Epoch 23/100\n",
      "30165/30165 [==============================] - 1s 50us/sample - loss: 0.0449 - acc: 0.9975\n",
      "Epoch 24/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0413 - acc: 0.9985\n",
      "Epoch 25/100\n",
      "30165/30165 [==============================] - 1s 47us/sample - loss: 0.0398 - acc: 0.9986\n",
      "Epoch 26/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0456 - acc: 0.9958\n",
      "Epoch 27/100\n",
      "30165/30165 [==============================] - 1s 48us/sample - loss: 0.0446 - acc: 0.9969\n",
      "Epoch 28/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0371 - acc: 0.9991\n",
      "Epoch 29/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0344 - acc: 0.9995\n",
      "Epoch 30/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0320 - acc: 0.9999\n",
      "Epoch 31/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.0320 - acc: 0.9996\n",
      "Epoch 32/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0326 - acc: 0.9993\n",
      "Epoch 33/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.0326 - acc: 0.9991\n",
      "Epoch 34/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0322 - acc: 0.9990\n",
      "Epoch 35/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0345 - acc: 0.9979\n",
      "Epoch 36/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0330 - acc: 0.9987\n",
      "Epoch 37/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0318 - acc: 0.9989\n",
      "Epoch 38/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0298 - acc: 0.9994\n",
      "Epoch 39/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0273 - acc: 0.9998\n",
      "Epoch 40/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0262 - acc: 0.9999\n",
      "Epoch 41/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0271 - acc: 0.9994\n",
      "Epoch 42/100\n",
      "30165/30165 [==============================] - 2s 50us/sample - loss: 0.0303 - acc: 0.9981\n",
      "Epoch 43/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0435 - acc: 0.9930\n",
      "Epoch 44/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0405 - acc: 0.9955\n",
      "Epoch 45/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0339 - acc: 0.9982\n",
      "Epoch 46/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0303 - acc: 0.9990\n",
      "Epoch 47/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "30165/30165 [==============================] - 2s 56us/sample - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "30165/30165 [==============================] - 1s 48us/sample - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "30165/30165 [==============================] - 1s 47us/sample - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "30165/30165 [==============================] - 2s 56us/sample - loss: 0.0208 - acc: 0.9999\n",
      "Epoch 53/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0219 - acc: 0.9997\n",
      "Epoch 55/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0292 - acc: 0.9970\n",
      "Epoch 56/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0297 - acc: 0.9971\n",
      "Epoch 57/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0391 - acc: 0.9942\n",
      "Epoch 58/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0359 - acc: 0.9962\n",
      "Epoch 59/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0284 - acc: 0.9990\n",
      "Epoch 60/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0241 - acc: 0.9999\n",
      "Epoch 61/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "30165/30165 [==============================] - 2s 56us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "30165/30165 [==============================] - 2s 55us/sample - loss: 0.0195 - acc: 0.9997\n",
      "Epoch 70/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0323 - acc: 0.9952\n",
      "Epoch 71/100\n",
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0302 - acc: 0.9967\n",
      "Epoch 72/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0360 - acc: 0.9944\n",
      "Epoch 73/100\n",
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0308 - acc: 0.9971\n",
      "Epoch 74/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0277 - acc: 0.9985\n",
      "Epoch 75/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0246 - acc: 0.9990\n",
      "Epoch 76/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0211 - acc: 0.9999\n",
      "Epoch 77/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "30165/30165 [==============================] - 2s 60us/sample - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30165/30165 [==============================] - 2s 60us/sample - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0157 - acc: 0.9999\n",
      "Epoch 86/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0162 - acc: 0.9998\n",
      "Epoch 87/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0265 - acc: 0.9958\n",
      "Epoch 88/100\n",
      "30165/30165 [==============================] - 2s 51us/sample - loss: 0.0280 - acc: 0.9959\n",
      "Epoch 89/100\n",
      "30165/30165 [==============================] - 2s 54us/sample - loss: 0.0397 - acc: 0.9921\n",
      "Epoch 90/100\n",
      "30165/30165 [==============================] - 2s 52us/sample - loss: 0.0315 - acc: 0.9959\n",
      "Epoch 91/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0244 - acc: 0.9985\n",
      "Epoch 92/100\n",
      "30165/30165 [==============================] - 2s 53us/sample - loss: 0.0207 - acc: 0.9997\n",
      "Epoch 93/100\n",
      "30165/30165 [==============================] - 2s 60us/sample - loss: 0.0187 - acc: 0.9999\n",
      "Epoch 94/100\n",
      "30165/30165 [==============================] - 2s 56us/sample - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30165/30165 [==============================] - 2s 58us/sample - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30165/30165 [==============================] - 2s 57us/sample - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30165/30165 [==============================] - 2s 59us/sample - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30165/30165 [==============================] - 2s 61us/sample - loss: 0.0143 - acc: 1.0000\n",
      "Training accuracy:1.0\n",
      "Testing accuracy:0.9292707443237305\n",
      "Training accuracy:0.9752610921859741\n",
      "Validation accuracy:0.9752610921859741\n",
      "Testing accuracy:0.8773226737976074\n",
      "total time: 1997.3140330314636\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_trial =10\n",
    "n_tr_list = [1000, 5000, 10000, 30000, 60000] # list of training sample sizes\n",
    "\n",
    "k=0\n",
    "K = len(n_tr_list)\n",
    "ERM_model_acc = np.zeros((K,n_trial))\n",
    "ERM_model_acc_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc = np.zeros((K,n_trial))\n",
    "IRM_model_acc_v = np.zeros((K,n_trial))\n",
    "IRM_model_ind_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc1 = np.zeros((K,n_trial))\n",
    "ERM_model_acc1_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc1 = np.zeros((K,n_trial))\n",
    "IRM_model_acc1_v = np.zeros((K,n_trial))\n",
    "IRM_model_ind_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc_av = np.zeros(K)\n",
    "ERM_model_acc_av_nb = np.zeros(K)\n",
    "IRM_model_acc_av = np.zeros(K)\n",
    "IRM_model_acc_av_v = np.zeros(K)\n",
    "\n",
    "\n",
    "ERM_model_acc_av1 = np.zeros(K)\n",
    "ERM_model_acc_av1_nb = np.zeros(K)\n",
    "IRM_model_acc_av1 = np.zeros(K)\n",
    "IRM_model_acc_av1_v = np.zeros(K)\n",
    "\n",
    "list_params = []\n",
    "for n_tr in n_tr_list:\n",
    "    print (\"tr\" + str(n_tr))\n",
    "    t_start = time.time()\n",
    "    for trial in range(n_trial):\n",
    "        print (\"trial \" + str(trial))\n",
    "        n_e=2\n",
    "        p_color_list = [0.2, 0.1]\n",
    "        p_label_list = [0.25]*n_e\n",
    "        D = assemble_data_mnist_sb(n_tr) # initialize mnist digits data object\n",
    "\n",
    "        D.create_training_data(n_e, p_color_list, p_label_list) # creates the training environments\n",
    "\n",
    "        p_label_test = 0.25 # probability of switching pre-label in test environment\n",
    "        p_color_test = 0.9  # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "        D.create_testing_data(p_color_test, p_label_test, n_e)  # sets up the testing environment\n",
    "        (num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "        num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data\n",
    "\n",
    "        model_erm =  keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        num_epochs = 100\n",
    "        batch_size = 512\n",
    "        learning_rate = 4.9e-4\n",
    "        erm_model1 = standard_erm_model(model_erm, num_epochs, batch_size, learning_rate)\n",
    "        erm_model1.fit(D.data_tuple_list)\n",
    "        erm_model1.evaluate(D.data_tuple_test)\n",
    "        print (\"Training accuracy:\" + str(erm_model1.train_acc))\n",
    "        print (\"Testing accuracy:\" + str(erm_model1.test_acc))\n",
    "        \n",
    "        ERM_model_acc[k][trial] = erm_model1.test_acc\n",
    "        ERM_model_acc1[k][trial] = erm_model1.train_acc\n",
    "\n",
    "\n",
    "        gamma_list = [10000, 33000, 66000,100000.0]\n",
    "        index=0\n",
    "        best_err = 1e6\n",
    "        train_list =[]\n",
    "        val_list = []\n",
    "        test_list = []\n",
    "        for gamma_new in gamma_list:\n",
    "\n",
    "            model_irm = keras.Sequential([\n",
    "                                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(num_classes)\n",
    "                        ])\n",
    "            batch_size       = 512\n",
    "            steps_max        = 1000\n",
    "            steps_threshold  = 190  ## threshold after which gamma_new is used\n",
    "            learning_rate    = 4.9e-4\n",
    "\n",
    "\n",
    "            irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "            irm_model1.fit(D.data_tuple_list)\n",
    "            irm_model1.evaluate(D.data_tuple_test)\n",
    "            error_val = 1-irm_model1.val_acc\n",
    "            train_list.append(irm_model1.train_acc)\n",
    "            val_list.append(irm_model1.val_acc)\n",
    "            test_list.append(irm_model1.test_acc)\n",
    "            if(error_val<best_err):\n",
    "                index_best =index\n",
    "                best_err = error_val\n",
    "            index= index+1\n",
    "\n",
    "        print (\"Training accuracy:\" + str(train_list[index_best]))\n",
    "        print (\"Validation accuracy:\" + str(val_list[index_best]))\n",
    "        print (\"Testing accuracy:\" + str(test_list[index_best]))\n",
    "\n",
    "        IRM_model_acc_v[k][trial]  = test_list[index_best]\n",
    "        IRM_model_acc1_v[k][trial] = train_list[index_best]\n",
    "        IRM_model_ind_v[k][trial]  = index_best\n",
    "\n",
    "\n",
    "    IRM_model_acc_av_v[k] = np.mean(IRM_model_acc_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_test\", np.mean(IRM_model_acc_v[k]),np.std(IRM_model_acc_v[k])])\n",
    "\n",
    "    ERM_model_acc_av[k] = np.mean(ERM_model_acc[k])\n",
    "    list_params.append([n_tr,\"ERM_test\", np.mean(ERM_model_acc[k]),np.std(ERM_model_acc[k])])\n",
    "\n",
    "\n",
    "    IRM_model_acc_av1_v[k] = np.mean(IRM_model_acc1_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_train\", np.mean(IRM_model_acc1_v[k]),np.std(IRM_model_acc1_v[k])])\n",
    "    \n",
    "    ERM_model_acc_av1[k] = np.mean(ERM_model_acc1[k])\n",
    "    list_params.append([n_tr, \"ERM_train\", np.mean(ERM_model_acc1[k]),np.std(ERM_model_acc1[k])])\n",
    "\n",
    "\n",
    "    k=k+1\n",
    "\n",
    "    t_end = time.time()\n",
    "    print(\"total time: \" + str(t_end-t_start))\n",
    "    \n",
    "\n",
    "\n",
    "results = pd.DataFrame(list_params, columns= [\"Sample\",\"Method\", \"Performance\", \"Sdev\"])\n",
    "ideal_error = np.zeros(5)\n",
    "\n",
    "print (\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01, 0.8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of samples\", fontsize=16)\n",
    "plt.ylabel(\"Test error\", fontsize=16)\n",
    "plt.plot(n_tr_list, 1-ERM_model_acc_av, \"-r\", marker=\"+\", label=\"ERM\")\n",
    "plt.plot(n_tr_list, 1-IRM_model_acc_av_v, \"-b\", marker=\"s\",label=\"IRMv1\")\n",
    "plt.plot(n_tr_list, ideal_error, \"-g\", marker=\"x\", label=\"Optimal invariant\")\n",
    "plt.legend(loc=\"upper left\", fontsize=18)\n",
    "plt.ylim(-0.01,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Method</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Sdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>IRMv_test</td>\n",
       "      <td>0.532615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>ERM_test</td>\n",
       "      <td>0.460476</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>IRMv_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>ERM_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>IRMv_test</td>\n",
       "      <td>0.790206</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>ERM_test</td>\n",
       "      <td>0.762193</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000</td>\n",
       "      <td>IRMv_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>ERM_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000</td>\n",
       "      <td>IRMv_test</td>\n",
       "      <td>0.856914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>ERM_test</td>\n",
       "      <td>0.838451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000</td>\n",
       "      <td>IRMv_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000</td>\n",
       "      <td>ERM_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30000</td>\n",
       "      <td>IRMv_test</td>\n",
       "      <td>0.895023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30000</td>\n",
       "      <td>ERM_test</td>\n",
       "      <td>0.908926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30000</td>\n",
       "      <td>IRMv_train</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30000</td>\n",
       "      <td>ERM_train</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60000</td>\n",
       "      <td>IRMv_test</td>\n",
       "      <td>0.877323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60000</td>\n",
       "      <td>ERM_test</td>\n",
       "      <td>0.929271</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60000</td>\n",
       "      <td>IRMv_train</td>\n",
       "      <td>0.975261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60000</td>\n",
       "      <td>ERM_train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample      Method  Performance  Sdev\n",
       "0     1000   IRMv_test     0.532615   0.0\n",
       "1     1000    ERM_test     0.460476   0.0\n",
       "2     1000  IRMv_train     1.000000   0.0\n",
       "3     1000   ERM_train     1.000000   0.0\n",
       "4     5000   IRMv_test     0.790206   0.0\n",
       "5     5000    ERM_test     0.762193   0.0\n",
       "6     5000  IRMv_train     1.000000   0.0\n",
       "7     5000   ERM_train     1.000000   0.0\n",
       "8    10000   IRMv_test     0.856914   0.0\n",
       "9    10000    ERM_test     0.838451   0.0\n",
       "10   10000  IRMv_train     1.000000   0.0\n",
       "11   10000   ERM_train     1.000000   0.0\n",
       "12   30000   IRMv_test     0.895023   0.0\n",
       "13   30000    ERM_test     0.908926   0.0\n",
       "14   30000  IRMv_train     0.990907   0.0\n",
       "15   30000   ERM_train     0.999074   0.0\n",
       "16   60000   IRMv_test     0.877323   0.0\n",
       "17   60000    ERM_test     0.929271   0.0\n",
       "18   60000  IRMv_train     0.975261   0.0\n",
       "19   60000   ERM_train     1.000000   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
